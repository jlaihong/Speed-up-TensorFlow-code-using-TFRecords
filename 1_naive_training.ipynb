{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UTMU565qzQS2"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import Model\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "import glob\n",
    "\n",
    "import PIL\n",
    "from PIL import Image\n",
    "\n",
    "import time\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure same GPU assigned by colab, for fair comparison\n",
    "\n",
    "!nvidia-smi -L"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mcv9J5Oc29wo"
   },
   "source": [
    "# 1. Gather and prepare the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RUMnEN6kNr5G"
   },
   "source": [
    "## 1.1 Download and Extract the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 18181,
     "status": "ok",
     "timestamp": 1629439238281,
     "user": {
      "displayName": "Jeremy Lai Hong",
      "photoUrl": "",
      "userId": "06292101247589650245"
     },
     "user_tz": -120
    },
    "id": "c98Zdwld3157",
    "outputId": "9620252f-55fe-4647-90ae-7f15df0b099a"
   },
   "outputs": [],
   "source": [
    "!gdown https://drive.google.com/u/0/uc?id=1STYsoP85lyKAtarMRuDyTjp89tAbIDM-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 13383,
     "status": "ok",
     "timestamp": 1629439251659,
     "user": {
      "displayName": "Jeremy Lai Hong",
      "photoUrl": "",
      "userId": "06292101247589650245"
     },
     "user_tz": -120
    },
    "id": "k0UVe5DV36MC",
    "outputId": "44b114b3-bc74-43c1-cedf-326f0d87ffe2"
   },
   "outputs": [],
   "source": [
    "!unzip -o caltech256_subset_resized_cropped256x256.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O2zc3MnI3NAb"
   },
   "outputs": [],
   "source": [
    "folder_paths = sorted(glob.glob(\"caltech256_subset_resized_cropped256x256/data/*\"))[:-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zZAk86KNNzwu"
   },
   "source": [
    "## 1.2 Split into training, validation and testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffled_paths = [] \n",
    "shuffled_labels = []\n",
    "\n",
    "with open(\"caltech256_subset_resized_cropped256x256/shuffled_labels.txt\") as label_file:\n",
    "    label_file_lines = label_file.readlines()\n",
    "    \n",
    "for line in label_file_lines:\n",
    "    image_path, image_label = line.strip().split(\",\")\n",
    "    shuffled_paths.append(image_path)\n",
    "    shuffled_labels.append(int(image_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7Fe21Q4t5dA7"
   },
   "outputs": [],
   "source": [
    "train_split = 0.6\n",
    "validation_split = 0.2\n",
    "\n",
    "num_train_images = int(len(shuffled_paths) * train_split)\n",
    "num_validation_images = int(len(shuffled_paths) * validation_split)\n",
    "\n",
    "train_image_names = shuffled_paths[:num_train_images]\n",
    "train_image_labels = np.array(shuffled_labels[:num_train_images])\n",
    "\n",
    "validation_image_names = shuffled_paths[num_train_images:num_train_images + num_validation_images]\n",
    "validation_image_labels = np.array(shuffled_labels[num_train_images:num_train_images + num_validation_images])\n",
    "\n",
    "test_image_names = shuffled_paths[num_train_images + num_validation_images:]\n",
    "test_image_labels = np.array(shuffled_labels[num_train_images + num_validation_images:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9wcS9VWRO5b-"
   },
   "source": [
    "## 1.3. Prepare data for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = 256\n",
    "crop_size = 224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cFIQZwoGHY4f"
   },
   "outputs": [],
   "source": [
    "# Load in the entire validation set: Assuming the entire validation set can fit into memory\n",
    "\n",
    "val_images = []\n",
    "\n",
    "for row in validation_image_names:\n",
    "    filename = row.split(\",\")[0]\n",
    "    \n",
    "    img = PIL.Image.open(\"caltech256_subset_resized_cropped256x256/data/\" + filename)\n",
    "    \n",
    "    val_images.append(np.array(img))\n",
    "\n",
    "crop_offset = (image_size - crop_size) // 2\n",
    "\n",
    "val_images = tf.image.crop_to_bounding_box(\n",
    "    np.array(val_images), crop_offset, crop_offset, crop_size, crop_size\n",
    ")\n",
    "\n",
    "validation_image_labels = np.array(validation_image_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gTXkyJBQPo4A"
   },
   "source": [
    "## 2. Build and Train a model for 10 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    inputs = layers.Input(shape=(crop_size, crop_size, 3))\n",
    "\n",
    "    pretrained_resnet_model = tf.keras.applications.resnet50.ResNet50(include_top=False, input_tensor=inputs)\n",
    "\n",
    "    pretrained_resnet_model.trainable = False\n",
    "\n",
    "    x = layers.GlobalAveragePooling2D()(pretrained_resnet_model.output)\n",
    "\n",
    "    x = layers.Dropout(0.2)(x)\n",
    "\n",
    "    outputs = layers.Dense(256, activation=\"softmax\")(x)\n",
    "\n",
    "    model = Model(inputs, outputs, name=\"ResNet\")\n",
    "\n",
    "    opt = tf.keras.optimizers.Adam(learning_rate=0.01)\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=opt, loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"]\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 107044,
     "status": "ok",
     "timestamp": 1629440260709,
     "user": {
      "displayName": "Jeremy Lai Hong",
      "photoUrl": "",
      "userId": "06292101247589650245"
     },
     "user_tz": -120
    },
    "id": "jmbVyeZD1-SP",
    "outputId": "9b05e77c-350c-4df1-8e0a-4bddd82b2787"
   },
   "outputs": [],
   "source": [
    "model = build_model()\n",
    "\n",
    "batch_size = 128\n",
    "\n",
    "initial_start = time.time()\n",
    "\n",
    "for epoch in range(10):\n",
    "    epoch_start = time.time()\n",
    "    \n",
    "    for start_index in range(0, len(train_image_names), batch_size):\n",
    "        end_index = start_index + batch_size\n",
    "\n",
    "        train_image_names_batch = train_image_names[start_index:end_index]\n",
    "        label_batch = train_image_labels[start_index:end_index]\n",
    "\n",
    "        images = []\n",
    "\n",
    "        for filename in train_image_names_batch:\n",
    "            img = PIL.Image.open(\"caltech256_subset_resized_cropped256x256/data/\" + filename)\n",
    "            img = tf.image.random_crop(np.array(img), size=[crop_size, crop_size, 3])\n",
    "            images.append(np.array(img))\n",
    "\n",
    "        images = np.array(images)\n",
    "\n",
    "        model.fit(images, label_batch, epochs=1, verbose=0, batch_size=128)\n",
    "\n",
    "    print(f\"Evaluating Validation Accuracy...\")\n",
    "    \n",
    "    model.evaluate(val_images, validation_image_labels)\n",
    "    \n",
    "    epoch_end = time.time()\n",
    "    \n",
    "    print(f\"Epoch Time: {epoch_end - epoch_start}\")\n",
    "\n",
    "last_end = time.time()\n",
    "\n",
    "print(last_end-initial_start)\n",
    "\n",
    "print(f\"Total Time: {last_end-initial_start}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "07I4XOgj7BNX"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyPbrxko/dw9rW/U/5YnlhfK",
   "collapsed_sections": [],
   "name": "1_cpu_to_gpu.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
